# 文章写作工作流

一个 PocketFlow 示例，演示了使用一系列 LLM 调用实现的文章写作工作流。

## 功能

- 使用 YAML 结构化输出生成一个最多包含 3 个主要部分的简单大纲
- 为每个部分撰写简洁（最多 100 字）的内容，并使用简单易懂的术语
- 为最终文章应用对话式、引人入胜的风格

## 入门指南

1. 安装所需的依赖项：

```bash
pip install -r requirements.txt
```

2. 将您的 OpenAI API 密钥设置为环境变量：

```bash
export OPENAI_API_KEY=your_api_key_here
```

3. 使用默认主题（“AI 安全”）运行应用程序：

```bash
python main.py
```

4. 或者指定您自己的主题：

```bash
python main.py 气候变化
```

## 工作原理

工作流由三个顺序节点组成：

```mermaid
graph LR
    Outline[生成大纲] --> Write[撰写内容]
    Write --> Style[应用样式]
```

每个节点的功能如下：

1. **生成大纲**：使用 YAML 结构化输出创建一个最多包含 3 个主要部分的简单大纲
2. **撰写简单内容**：为每个部分撰写简洁的 100 字解释
3. **应用样式**：以对话式、引人入胜的风格重写组合内容

## 文件

- [`main.py`](./main.py)：运行文章工作流的主入口点
- [`flow.py`](./flow.py)：定义连接节点的流
- [`nodes.py`](./nodes.py)：包含工作流中每个步骤的节点类
- [`utils/call_llm.py`](./utils/call_llm.py)：LLM 实用函数
- [`requirements.txt`](./requirements.txt)：列出所需的依赖项

## 示例输出

```
=== 正在启动关于主题：AI 安全的文章工作流 ===


===== 大纲 (YAML) =====

sections:
- AI 安全简介
- AI 安全的关键挑战
- 确保 AI 安全的策略


===== 解析后的大纲 =====

1. AI 安全简介
2. AI 安全的关键挑战
3. 确保 AI 安全的策略

=========================


===== 部分内容 =====

--- AI 安全简介 ---
AI 安全旨在确保人工智能 (AI) 系统有益无害。想象一下教机器人做家务。AI 安全就像为机器人设定基本规则，这样它就不会意外地惹麻烦，比如把宠物误认为是玩具。通过确保 AI 系统理解其任务和限制，我们可以相信它们能够安全地运行。它旨在创建指导方针和检查，以确保 AI 在没有意外后果的情况下协助我们。

--- AI 安全的关键挑战 ---
AI 安全旨在确保人工智能系统以有益无害的方式运行。一个关键挑战是确保 AI 做出的决策与人类价值观保持一致。想象一下教机器人去拿咖啡，但它却因为不理解自己造成的混乱而把东西撞倒。同样，如果 AI 系统不能完全理解人类意图，它们可能会以意想不到的方式行事。任务是让 AI 足够智能，能够实现目标而不会造成问题，就像训练小狗遵守规则而不会啃咬你的鞋子一样。

--- 确保 AI 安全的策略 ---
确保 AI 安全旨在确保人工智能按预期运行，并且不会造成伤害。想象一下 AI 就像一个新上路的司机；我们需要规则和保障措施来防止事故。通过在不同条件下测试 AI 系统，为它们的行为设定明确的规则，并保持人工监督，我们可以管理风险。例如，就像汽车有刹车以确保安全一样，AI 系统也需要有故障保护。这有助于建立信任并避免意外问题，使人类和 AI 都保持在正确的轨道上。

===========================


===== 最终文章 =====

# 欢迎来到 AI 安全的世界

你有没有想过拥有一个自己的机器人帮你做家务会是什么样子？听起来像个梦想，对吧？但让我们暂停一下。如果这个机器人把你的毛茸茸的猫误认为是玩具怎么办？这正是 AI 安全的用武之地。把 AI 安全想象成给你的家庭助手设定一些友好的基本规则，确保它知道做家务和制造一点混乱之间的区别。这一切都是为了确保我们的 AI 盟友遵守规则，让生活更轻松，而不会出现那些烦人的意外小插曲。

# 驾驭 AI 挑战的迷宫

想象一下：你让你的忠实机器人去给你拿杯咖啡。但它却把杯子撞飞，把咖啡洒了一地，因为它根本不理解“混乱”这个概念。这令人沮丧，不是吗？AI 安全最大的障碍之一是让 AI 的决策与我们人类的价值观和意图保持一致。这就像训练小狗不要啃咬你最喜欢的鞋子一样。我们的任务是教 AI 如何在不踩到我们脚趾的情况下实现其目标，同时像训练有素的小狗一样可靠和可爱。

# 引导 AI 走向安全的未来

那么，我们如何让我们的 AI 朋友走上正轨呢？想象一下 AI 就像一个新司机，正在学习如何在生活的道路上行驶。就像我们教新司机道路规则并为汽车配备刹车以确保安全一样，我们为 AI 提供指导方针和故障保护，以防止任何意外事故。在各种场景中测试 AI 系统并对其保持警惕的人工监督，可以确保它们不会偏离轨道。这一切都是为了建立信任并建立一种伙伴关系，在这种伙伴关系中，人类和 AI 都能顺利地共同前进。

# 总结

归根结底，AI 安全旨在创建人类与机器之间的和谐关系，在这种关系中，我们相信我们的金属伙伴能够支持我们，而无需担心意外的发生。通过设定界限和确保理解，我们不仅在构建更智能的机器，还在创造一个 AI 和人类可以共同繁荣的未来。所以，下次当你想象那个乐于助人的机器人助手时，请放心，AI 安全正在确保它随时准备伸出援手，而不会掉链子——或者你的咖啡杯！

========================


=== 工作流完成 ===

主题：AI 安全
大纲长度：96 个字符
草稿长度：1690 个字符
最终文章长度：2266 个字符
```
