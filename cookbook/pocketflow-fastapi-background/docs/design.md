# Design Doc: PocketFlow FastAPI Background Job with SSE Progress

> Please DON'T remove notes for AI

## 需求

> 给AI的提示：保持简单清晰
> 如果需求比较抽象，请编写具体的用户故事

**用户故事**：作为一个用户，我想通过Web API提交文章主题，并在文章生成过程中接收实时进度更新，这样我可以在不阻塞UI的情况下查看工作流进度。

**核心需求**：
1. 通过REST API端点提交文章主题
2. 启动文章生成工作流的后台任务
3. 通过服务器发送事件(SSE)接收实时进度更新
4. 在工作流完成时获取最终文章结果
5. 处理多个并发请求

**技术要求**：
- 使用FastAPI搭建Web服务器并提供REST端点
- 使用asyncio进行后台任务处理
- 使用服务器发送事件(SSE)进行进度流式传输
- 提供简单的Web界面来测试功能

## 流程设计

> 给AI的提示：
> 1. 考虑代理、map-reduce、rag和工作流等设计模式，如果适用就采用
> 2. 提供工作流的高层次简洁描述

### 适用的设计模式：

**工作流模式**：按顺序处理文章生成步骤，并在每个阶段报告进度

### 高层次流程设计：

1. **生成大纲节点**：为文章主题创建结构化大纲
2. **编写内容节点**：为大纲中的每个部分编写内容
3. **应用样式节点**：为最终文章应用对话式风格

每个节点都将进度更新放入asyncio.Queue中以进行SSE流式传输。

```mermaid
flowchart LR
    outline[Generate Outline] --> content[Write Content]
    content --> styling[Apply Style]
```

## 实用函数

> 给AI的提示：
> 1. 通过查阅文档，彻底理解实用函数的定义
> 2. 仅包含基于流程中节点的必要实用函数

1. **调用LLM** (`utils/call_llm.py`)
   - *输入*：提示 (str)
   - *输出*：响应 (str)
   - 所有工作流节点都使用此函数执行LLM任务

## 节点设计

### 共享存储

> 给AI的提示：尽量减少数据冗余

共享存储结构如下：

```python
shared = {
    "topic": "用户提供的主题",
    "sse_queue": asyncio.Queue(),  # 用于发送SSE更新
    "sections": ["第一部分", "第二部分", "第三部分"],
    "draft": "组合后的内容",
    "final_article": "风格化后的最终文章"
}
```

### 节点步骤

> 给AI的提示：仔细决定是否使用批处理/异步节点/流。

1. **生成大纲节点**
   - *目的*：使用YAML输出创建包含3个主要部分的结构化大纲
   - *类型*：常规节点（同步LLM调用）
   - *步骤*：
     - *prep*：从共享存储中读取“topic”
     - *exec*：调用LLM生成YAML大纲，解析并验证结构
     - *post*：将“sections”写入共享存储，将进度更新放入sse_queue

2. **编写内容节点**
   - *目的*：为每个大纲部分生成简洁的内容
   - *类型*：批处理节点（独立处理每个部分）
   - *步骤*：
     - *prep*：从共享存储中读取“sections”（返回部分列表）
     - *exec*：对于一个部分，调用LLM编写100字内容
     - *post*：将所有部分内容组合成“draft”，将进度更新放入sse_queue

3. **应用样式节点**
   - *目的*：将对话式、引人入胜的风格应用于组合内容
   - *类型*：常规节点（单个LLM调用进行样式设置）
   - *步骤*：
     - *prep*：从共享存储中读取“draft”
     - *exec*：调用LLM以对话式风格重写
     - *post*：将“final_article”写入共享存储，将完成更新放入sse_queue
